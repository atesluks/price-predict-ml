{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e4887b-1bad-4299-aa8a-7f06d0bbebf4",
   "metadata": {},
   "source": [
    "### Predicting BTC price for the next 2 months from the last 8 hours (hourly) market data.\n",
    "#### Model: Multi-model.\n",
    "\n",
    "#### Input: Last 8 hours of hourly data of BTC price and 24-volume.\n",
    "\n",
    "#### Output: Predicted BTC price in two months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14f449-03ea-46c0-a759-d6cf358fd44a",
   "metadata": {},
   "source": [
    "## 0. Importing libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9daa18-e0a9-4a7c-93fe-e9f14e764b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', '..')))\n",
    "\n",
    "from app.database import SessionLocal\n",
    "from app.models import DataCGCoinsMarketChart1h, Logs\n",
    "import mlflow\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = \"07_btc_2m_from_btc_8h_multi_dev\"\n",
    "MODEL_DESCRIPTION = \"Predicting BTC price for the next 2 months from the last 8 hours (hourly) market data.\"\n",
    "INPUT_DESCRIPTION = \"Last 8 hours of hourly data of BTC price and 24-volume.\"\n",
    "OUTPUT_DESCRIPTION = \"Predicted BTC price in the next 2 months.\"\n",
    "\n",
    "SOURCE_NAME = \"data_cg_coins_market_chart_1h\"\n",
    "SOURCE_COLUMNS = [\"Time\", \"Price\", \"24h_Volume\"]\n",
    "\n",
    "RETRAIN_INTERVAL = \"1 hour\"\n",
    "TRAIN_SET_RATIO = 0.9\n",
    "N_TEST = 92 # Number of testing data points\n",
    "LAGS = 3 #8\n",
    "\n",
    "CROSS_VAL_SPLIT = 5\n",
    "OPTUNA_TRIALS = 30 #50\n",
    "RANDOM_SEARCH_N_ITER = 10\n",
    "PRUNER_PATIENCE = 10\n",
    "\n",
    "HOURS_AHEAD_TO_PREDICT = 1440\n",
    "\n",
    "OPTIMIZE_RANDOM_SEARCH = True\n",
    "OPTIMIZE_BAYES_OPT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865afe6-7a05-49b6-88b9-4b31830d13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "start_time_general = time.time()\n",
    "\n",
    "# Logging\n",
    "mlflow.set_tracking_uri(uri=os.getenv('MLFLOW_URL'))\n",
    "mlflow.set_experiment(\"2 months BTC prediction\")\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abc544-d285-4500-81a5-9b3262a069fa",
   "metadata": {},
   "source": [
    "## 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23c639-67c8-4687-99e8-baf28f321557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "def load_data_from_db(pair):\n",
    "    session = SessionLocal()\n",
    "    try:\n",
    "        data = session.query(DataCGCoinsMarketChart1h)\\\n",
    "            .filter(DataCGCoinsMarketChart1h.pair == pair)\\\n",
    "            .order_by(DataCGCoinsMarketChart1h.time.desc())\\\n",
    "            .all()\n",
    "        \n",
    "        df = pd.DataFrame([{\n",
    "            'Time': record.time,\n",
    "            'Pair': record.pair,\n",
    "            'Price': record.price,\n",
    "            '24h_Volume': record.volume\n",
    "        } for record in data])\n",
    "        \n",
    "        df.set_index('Time', inplace=True)\n",
    "        df.sort_index(ascending=True, inplace=True)\n",
    "        return df\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Load the data\n",
    "df = load_data_from_db(\"BTC-USD\")\n",
    "\n",
    "# Validating no redundant data\n",
    "print(len(df[df[\"Pair\"] != \"BTC-USD\"].head())) # How many non BTC-USD pair records\n",
    "\n",
    "# Dropping Pair column\n",
    "df = df.drop(columns='Pair')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4cc5c-d95e-4003-97df-c0ffe535a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636967d-eecf-4c62-95a6-9069026e1b29",
   "metadata": {},
   "source": [
    "## 2. Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06420c-6dcc-4fc7-9c41-1ce55899d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f97f4-d865-46bc-b661-e11a45904d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_price_lag = HOURS_AHEAD_TO_PREDICT - 1\n",
    "\n",
    "# Create lagged features for the last 12 hours\n",
    "def create_lagged_features(df, lags):\n",
    "    for lag in range(1, lags + 1):\n",
    "        df[f'Price_lag_{lag}'] = df['Price'].shift(lag)\n",
    "        df[f'24h_Volume_lag_{lag}'] = df['24h_Volume'].shift(lag)\n",
    "\n",
    "    df[f'Price_in_{HOURS_AHEAD_TO_PREDICT}_h'] = df['Price'].shift(-prediction_price_lag)\n",
    "    \n",
    "    # Drop rows with any NaN values created by the lagging process\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "df_lagged = create_lagged_features(df, lags=LAGS)\n",
    "df_lagged = df_lagged.drop(columns=\"24h_Volume\")\n",
    "df_lagged = df_lagged.drop(columns=\"Price\")\n",
    "\n",
    "print(len(df_lagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247256cc-6a49-442a-b05f-f40df80952a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f43c2-5dfe-4cb3-9601-a5d605bb1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values, again\n",
    "df_lagged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0463491-0ffb-4ddf-8adb-1d37c8de35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training, validation and testing datasets\n",
    "df_lagged = df_lagged.sort_index(ascending=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_lagged.drop(columns=f'Price_in_{HOURS_AHEAD_TO_PREDICT}_h')\n",
    "y = df_lagged[f'Price_in_{HOURS_AHEAD_TO_PREDICT}_h']\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "n_train = len(df_lagged) - N_TEST\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Total dataset size: {len(df_lagged)}\")\n",
    "print(f\"Training set size: {len(X_train)} (should be {round(len(df_lagged) * TRAIN_SET_RATIO)})\")\n",
    "print(f\"Testing set size: {len(X_test)} (should be {round(len(df_lagged) * (1 - TRAIN_SET_RATIO))})\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee063307-d7f7-449e-b304-57430efbd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20aeb9e-076e-4011-aa00-78773c8295bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dca5a0-aef0-4259-a4bd-5184f71287f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(data):\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the data\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    return scaler, scaled_data\n",
    "\n",
    "# Fit and scale on the training data\n",
    "scaler, X_train_scaled = scale(X_train)\n",
    "\n",
    "# Scale the validation data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd51578-4d1c-42cb-a7d9-5ec6cc217fce",
   "metadata": {},
   "source": [
    "## 3. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3447984-a809-44f7-a55f-8697f4b4e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def parse_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    minutes = int(minutes)\n",
    "    seconds = round(seconds)\n",
    "\n",
    "    if minutes == 0:\n",
    "        return f\"{seconds}s\"\n",
    "    else:\n",
    "        return f\"{int(minutes)}m {seconds}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e6759-f1e2-4bf7-9869-62e305aa2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression,\n",
    "    SGDRegressor, PassiveAggressiveRegressor, HuberRegressor, QuantileRegressor,\n",
    "    RANSACRegressor, TheilSenRegressor, PoissonRegressor, GammaRegressor, TweedieRegressor\n",
    ")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor,\n",
    "    AdaBoostRegressor, HistGradientBoostingRegressor\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    \"LinearRegression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"RidgeRegression\": {\n",
    "        \"model\": Ridge(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 30.0, 50.0, 70.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    \"LassoRegression\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 30.0, 50.0, 70.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    \"ElasticNet\": {\n",
    "        \"model\": ElasticNet(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"BayesianRidge\": {\n",
    "        \"model\": BayesianRidge(),\n",
    "        \"params\": {\n",
    "            'n_iter': [100, 300, 500, 1000],\n",
    "            'alpha_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'alpha_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'lambda_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'lambda_2': [1e-6, 1e-5, 1e-4, 1e-3]\n",
    "        }\n",
    "    },\n",
    "    \"ARDRegression\": {\n",
    "        \"model\": ARDRegression(),\n",
    "        \"params\": {\n",
    "            'n_iter': [100, 300, 500, 1000],\n",
    "            'alpha_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'alpha_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'lambda_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "            'lambda_2': [1e-6, 1e-5, 1e-4, 1e-3]\n",
    "        }\n",
    "    },\n",
    "    \"SGDRegressor\": {\n",
    "        \"model\": SGDRegressor(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "            'eta0': [0.01, 0.1, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"PassiveAggressiveRegressor\": {\n",
    "        \"model\": PassiveAggressiveRegressor(),\n",
    "        \"params\": {\n",
    "            'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'epsilon': [0.01, 0.1, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"HuberRegressor\": {\n",
    "        \"model\": HuberRegressor(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "            'epsilon': [1.35, 1.5, 1.75, 2.0]\n",
    "        }\n",
    "    },\n",
    "    \"QuantileRegressor\": {\n",
    "        \"model\": QuantileRegressor(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'quantile': [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "        }\n",
    "    },\n",
    "    \"RANSACRegressor\": {\n",
    "        \"model\": RANSACRegressor(),\n",
    "        \"params\": {\n",
    "            'min_samples': [0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "            'residual_threshold': [None, 1.0, 2.0, 5.0, 10.0],\n",
    "            'max_trials': [100, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    # This is the best model, but run too long in random search (e.g. 16 minutes, while other run max 1 min, but mostly below that)\n",
    "    # \"TheilSenRegressor\": {\n",
    "    #     \"model\": TheilSenRegressor(),\n",
    "    #     \"params\": {\n",
    "    #         'max_subpopulation': [1e3, 1e4, 1e5, 1e6],\n",
    "    #         'n_subsamples': [None, 100, 300, 500, 1000],\n",
    "    #         'max_iter': [300, 500, 1000],\n",
    "    #         'tol': [1e-3, 1e-4, 1e-5]\n",
    "    #     }\n",
    "    # },\n",
    "    \"PoissonRegressor\": {\n",
    "        \"model\": PoissonRegressor(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'max_iter': [100, 300, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    \"GammaRegressor\": {\n",
    "        \"model\": GammaRegressor(),\n",
    "        \"params\": {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "            'max_iter': [100, 300, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    \"TweedieRegressor\": {\n",
    "        \"model\": TweedieRegressor(),\n",
    "        \"params\": {\n",
    "            'power': [0, 1, 1.5, 2, 3],\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "            'max_iter': [100, 300, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    # Commenting out this model for now because there are issues with pipeline\n",
    "    # (when using .__class__ it returns a pipeline, therefore cannot just initilize\n",
    "    # a fresh model from it\n",
    "    # \"PolynomialRegression\": {\n",
    "    #     \"model\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "    #     \"params\": {}\n",
    "    # },\n",
    "    \"SVR\": {\n",
    "        \"model\": SVR(),\n",
    "        \"params\": {\n",
    "            'C': [0.1, 1.0, 10.0, 100.0],\n",
    "            'epsilon': [0.01, 0.1, 0.2, 0.5],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto']  # Only for 'rbf', 'poly', and 'sigmoid' kernels\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        \"model\": DecisionTreeRegressor(),\n",
    "        \"params\": {\n",
    "            'max_depth': [None, 10, 20, 30, 50],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 10]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"model\": RandomForestRegressor(),\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100, 200, 500],\n",
    "            'max_depth': [None, 10, 20, 30, 50],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 10],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        \"model\": ExtraTreesRegressor(),\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100, 200, 500],\n",
    "            'max_depth': [None, 10, 20, 30, 50],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 10],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        \"model\": GradientBoostingRegressor(),\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100, 200, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7, 10],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4, 10]\n",
    "        }\n",
    "    },\n",
    "    \"AdaBoostRegressor\": {\n",
    "        \"model\": AdaBoostRegressor(),\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100, 200, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "            'loss': ['linear', 'square', 'exponential']\n",
    "        }\n",
    "    },\n",
    "    \"HistGradientBoostingRegressor\": {\n",
    "        \"model\": HistGradientBoostingRegressor(),\n",
    "        \"params\": {\n",
    "            'max_iter': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_leaf': [10, 20, 30],\n",
    "            'l2_regularization': [0.0, 0.1, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighborsRegressor\": {\n",
    "        \"model\": KNeighborsRegressor(),\n",
    "        \"params\": {\n",
    "            'n_neighbors': [3, 5, 7, 10, 15],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'leaf_size': [20, 30, 40]\n",
    "        }\n",
    "    },\n",
    "    # need more testing and optimization, it throws many different errors and warning because of different kernels\n",
    "    # \"GaussianProcessRegressor\": {\n",
    "    #     \"model\": GaussianProcessRegressor(),\n",
    "    #     \"params\": {\n",
    "    #         'alpha': [1e-10, 1e-5, 1e-2, 0.1, 1.0, 10.0, 100.0],\n",
    "    #         'kernel': [RBF(length_scale_bounds=(1e-2, 1e5)),\n",
    "    #                    Matern(length_scale_bounds=(1e-2, 1e5)),\n",
    "    #                    RationalQuadratic(length_scale_bounds=(1e-2, 1e5)),\n",
    "    #                    ExpSineSquared(length_scale_bounds=(1e-2, 1e5))],\n",
    "    #         'n_restarts_optimizer': [0, 1, 2, 5]\n",
    "    #     }\n",
    "    # },\n",
    "    \"MLPRegressor\": {\n",
    "        \"model\": MLPRegressor(),\n",
    "        \"params\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (50, 100)],\n",
    "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "            'max_iter': [200, 300, 500]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "random_search_start_time = time.time()\n",
    "\n",
    "# Training data being split for window cross-validation (specific for time series type of data)\n",
    "tscv = TimeSeriesSplit(n_splits=CROSS_VAL_SPLIT)\n",
    "\n",
    "# Train and test each model with random search\n",
    "for model_name, model_dict in models.items():\n",
    "    model = model_dict[\"model\"]\n",
    "    param_distributions = model_dict[\"params\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if param_distributions:\n",
    "        # Perform random search if there are hyperparameters to tune\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, \n",
    "            param_distributions, \n",
    "            n_iter=RANDOM_SEARCH_N_ITER, \n",
    "            cv=tscv,\n",
    "            scoring='neg_mean_squared_error', \n",
    "            random_state=42,\n",
    "            n_jobs= -1 if OPTIMIZE_RANDOM_SEARCH else None\n",
    "        )\n",
    "        random_search.fit(X_train_scaled, y_train)\n",
    "        best_model = random_search.best_estimator_\n",
    "        best_params = random_search.best_params_\n",
    "        score = -random_search.best_score_ \n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_diff = end_time - start_time\n",
    "        \n",
    "        # Collecting results for all tried hyperparameters\n",
    "        for i in range(len(random_search.cv_results_['mean_test_score'])):\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'params': random_search.cv_results_['params'][i],\n",
    "                'mse_score': -random_search.cv_results_['mean_test_score'][i],\n",
    "                'time_spent_seconds': time_diff,\n",
    "            })\n",
    "\n",
    "        print(f\"{model_name} - Best Params: {best_params} - MSE: {score:.10f} - Time Spent: {parse_time(time_diff)} seconds\")\n",
    "    else:\n",
    "        # Manually fit the model with sliding window cross-validation\n",
    "        score_results = []\n",
    "        best_model = model\n",
    "        for train_index, test_index in tscv.split(X_train_scaled):\n",
    "            X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict on the test fold and collect results\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            score_fold = mean_squared_error(y_test_fold, y_pred_fold)\n",
    "\n",
    "            score_results.append(score_fold)\n",
    "        \n",
    "        # Record result for the current fold\n",
    "        end_time = time.time()\n",
    "        time_diff = end_time - start_time\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'params': {},  # No hyperparameters in this case\n",
    "            'mse_score': sum(score_results) / len(score_results), # average from the scores from each cross-validation folds\n",
    "            'time_spent_seconds': time_diff,\n",
    "        })\n",
    "    \n",
    "        print(f\"{model_name} - MSE: {score:.10f} - Time Spent: {parse_time(time_diff)} seconds\")\n",
    "\n",
    "# record random search time results\n",
    "random_search_end_time = time.time()\n",
    "random_search_total_time = parse_time(random_search_end_time - random_search_start_time)\n",
    "\n",
    "# Convert results to a DataFrame for better readability\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['time_spent'] = results_df['time_spent_seconds'].apply(parse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27dffd-08e0-4f5d-94cd-9252f2621d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Random Search total time: {random_search_total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7ba18-9766-4d0d-944e-c028aa671ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time spent on Random Search for each model\n",
    "random_search_all_models_by_time = results_df.drop_duplicates('model').sort_values(by='time_spent_seconds', ascending=False)\n",
    "random_search_all_models_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca4520-a9fb-47c7-9b11-ab358b53bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_all_model_variations_by_score = results_df.sort_values(by='mse_score')\n",
    "random_search_all_model_variations_by_score[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e6190-08ff-4035-9741-68a45499d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 models by MSE score, ensuring no duplicate model types\n",
    "random_search_top_10_models_by_score = random_search_all_model_variations_by_score.drop_duplicates('model').head(10)\n",
    "random_search_top_10_models_by_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203f59a-5011-481c-8872-74483d70cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_top10_total_time = parse_time(random_search_top_10_models_by_score[\"time_spent_seconds\"].sum())\n",
    "print(f\"Random search top10 time: {random_search_top10_total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfd9ff-374f-4762-a415-3077c80af815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# Define a function to perform Optuna optimization for a given model and its hyperparameters\n",
    "def objective(trial, model_class, param_distributions, best_params):\n",
    "    model_params = {}\n",
    "    for param, value in best_params.items():\n",
    "        if isinstance(value, bool): # boolean is a subclass of int, so this check should come first\n",
    "            model_params[param] = trial.suggest_categorical(param, param_distributions[param])\n",
    "        elif value is None:\n",
    "            # Treat None as a categorical option\n",
    "            model_params[param] = trial.suggest_categorical(param, [None] + param_distributions[param])\n",
    "        elif isinstance(value, (int, float)):\n",
    "            max_bound = max(v for v in param_distributions[param] if v is not None)\n",
    "            min_bound = min(v for v in param_distributions[param] if v is not None)\n",
    "\n",
    "            # Searching in the area of the best_value (found in the random search) +/-10% of the whole range\n",
    "            range_frac = (max_bound - min_bound) * 0.1\n",
    "            \n",
    "            if isinstance(value, int):\n",
    "                # Ensure lower bound is not below min value in param distribution\n",
    "                lower_bound = max(min_bound, int(value - range_frac)) \n",
    "                \n",
    "                # Ensure upper bound is not above max value in param distribution, and is higher than lower bound\n",
    "                upper_bound = min(max_bound, max(lower_bound + 1, int(value + range_frac)))\n",
    "                \n",
    "                model_params[param] = trial.suggest_int(param, lower_bound, upper_bound)\n",
    "            elif isinstance(value, float):\n",
    "                # Ensure lower bound is not below min value in param distribution\n",
    "                lower_bound = max(min_bound, value - range_frac) \n",
    "                \n",
    "                # Ensure upper bound is not above max value in param distribution, and is higher than lower bound\n",
    "                upper_bound = min(max_bound, max(lower_bound + 0.01, value + range_frac))\n",
    "                    \n",
    "                model_params[param] = trial.suggest_float(param, lower_bound, upper_bound)\n",
    "        else:\n",
    "            model_params[param] = trial.suggest_categorical(param, param_distributions[param])\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        score = mean_squared_error(y_test, y_pred)\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        # If a LinAlgError occurs, assign a high error value to penalize this trial\n",
    "        score = float('inf')\n",
    "    return score\n",
    "\n",
    "# Initialize a list to store results\n",
    "optimization_results = []\n",
    "bayes_opt_start_time = time.time()\n",
    "\n",
    "# Perform Bayesian optimization for each of the top 10 models\n",
    "def optimize_model(row):\n",
    "    model_name = row['model']\n",
    "    model_class = models[model_name][\"model\"].__class__\n",
    "    param_distributions = models[model_name][\"params\"]\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    if param_distributions:\n",
    "        best_params = row['params']\n",
    "        pruner = optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=PRUNER_PATIENCE)\n",
    "        study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "        study.optimize(lambda trial: objective(trial, model_class, param_distributions, best_params), n_trials=OPTUNA_TRIALS)\n",
    "        \n",
    "        # Store the results\n",
    "        best_trial_params = study.best_trial.params\n",
    "        score = study.best_trial.value\n",
    "        time_diff = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'model_name': model_name,\n",
    "            'best_params': best_trial_params,\n",
    "            'best_score': score,\n",
    "            'best_model': model_class(**best_trial_params),\n",
    "            'time_spent_seconds': time_diff\n",
    "        }\n",
    "\n",
    "        print(f\"{model_name}: Best params - {best_trial_params}, MSE - {score:.10f}, time - {parse_time(time_diff)} seconds\")\n",
    "    else:\n",
    "        # Directly fit the model if no hyperparameters to tune\n",
    "        score = row['mse_score']\n",
    "        time_diff = time.time() - start_time\n",
    "\n",
    "        # Store the results\n",
    "        result = {\n",
    "            'model_name': model_name,\n",
    "            'best_params': {},\n",
    "            'best_score': score,\n",
    "            'best_model': model_class(),\n",
    "            'time_spent_seconds': time_diff\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n\\n\\n{model_name}: MSE - {score:.10f}, time - {parse_time(time_diff)} seconds\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Perform Bayesian optimization for each of the top 10 models in parallel\n",
    "if OPTIMIZE_BAYES_OPT:\n",
    "    optimization_results = Parallel(n_jobs=-1)(delayed(optimize_model)(row) for _, row in random_search_top_10_models_by_score.iterrows())\n",
    "else:\n",
    "    # not optimized (for testing only)\n",
    "    for _, row in random_search_top_10_models_by_score.iterrows():\n",
    "        optimization_results.append(optimize_model(row))\n",
    "\n",
    "bayes_opt_end_time = time.time()\n",
    "bayes_opt_total_time = parse_time(bayes_opt_end_time - bayes_opt_start_time)\n",
    "\n",
    "print(\"Optimization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ca67b-bf82-4015-8f14-1ad501e79b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bayesian optimization total time: {bayes_opt_total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e43a44-5327-4eaf-af15-a0eeafdb0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert optimization results to a DataFrame for better readability and sorting\n",
    "optimization_results_df = pd.DataFrame([{\n",
    "    'model_name': result['model_name'],\n",
    "    'best_params': result['best_params'],\n",
    "    'best_score': result['best_score'],\n",
    "    'time_spent_seconds': result['time_spent_seconds'],\n",
    "} for result in optimization_results])\n",
    "\n",
    "optimization_results_df['time_spent'] = optimization_results_df['time_spent_seconds'].apply(parse_time)\n",
    "\n",
    "# Sort the results by the best_score (MSE)\n",
    "optimization_results_df = optimization_results_df.sort_values(by='best_score').reset_index(drop=True)\n",
    "\n",
    "# Selecting the best model from Bayesian optimization\n",
    "best_model_name = optimization_results_df.iloc[0]['model_name']\n",
    "\n",
    "optimization_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64aa04c-95ea-4bfd-be16-adb258ea2598",
   "metadata": {},
   "source": [
    "## 4. Predicting and Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145d8e7-be2c-4c1d-9ba7-45b51d68663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    # Calculating performance metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # MAPE as a percentage\n",
    "    \n",
    "    ssr = np.sum((y_test - y_pred) ** 2)  # Sum of squares of residuals\n",
    "    sst = np.sum((y_test - np.mean(y_test)) ** 2)  # Total sum of squares\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Model MSE on test set: {mse:.12f}\")\n",
    "    print(f\"Model MAE on test set: {mae:.8f}\")\n",
    "    print(f\"Model RMSE on test set: {rmse:.8f}\")\n",
    "    print(f\"Model MAPE on test set: {mape:.2f}%\")\n",
    "    print(f\"Model R-squared on test set: {r2 * 100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "    return mse, mae, rmse, mape, r2\n",
    "\n",
    "mse, mae, rmse, mape, r2 = None, None, None, None, None\n",
    "best_model = None\n",
    "\n",
    "for result in optimization_results:\n",
    "    curr_model_name = result['model_name']\n",
    "    print(f\"Model: {curr_model_name}\")\n",
    "    print(f\"Best Params: {result['best_params']}\")\n",
    "    \n",
    "    model = result['best_model'].fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    if curr_model_name == best_model_name:\n",
    "        mse, mae, rmse, mape, r2 = evaluate(y_test, y_pred)\n",
    "        best_model = result['best_model'].__class__(**result['best_params'])\n",
    "    else:\n",
    "        evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47146d43-5935-451b-ac7d-b7803473c850",
   "metadata": {},
   "source": [
    "## 5. Getting the best model and retraining it on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a2555-aa43-43df-9e33-61a34f30b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler, X_scaled = scale(X)\n",
    "print(X_scaled.shape)\n",
    "\n",
    "model = best_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e60a4d-8b94-434d-b119-fbb2de3b13f4",
   "metadata": {},
   "source": [
    "## 6. Logging to MLFlow (saving the model and the scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f18f3-a1cb-4ef0-b4a1-a97d37eef697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Save the scaler to a file\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "if not os.path.exists(f'data/{MODEL_NAME}'):\n",
    "    os.makedirs(f'data/{MODEL_NAME}')\n",
    "    \n",
    "scaler_path = f\"data/{MODEL_NAME}/scaler.joblib\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = parse_time(end_time - start_time_general)\n",
    "\n",
    "# Log the scaler as an additional artifact\n",
    "mlflow.log_artifact(scaler_path, artifact_path=\"scaler\")\n",
    "\n",
    "# Set tags\n",
    "mlflow.set_tag(\"Model name\", MODEL_NAME)\n",
    "mlflow.set_tag(\"mlflow.note.content\", MODEL_DESCRIPTION)\n",
    "mlflow.set_tag(\"Model type\", best_model_name)\n",
    "mlflow.set_tag(\"Lags\", LAGS)\n",
    "mlflow.set_tag(\"Input description\", INPUT_DESCRIPTION)\n",
    "mlflow.set_tag(\"Output description\", OUTPUT_DESCRIPTION)\n",
    "mlflow.set_tag(\"Train data points\", n_train)\n",
    "mlflow.set_tag(\"Test data points\", N_TEST)\n",
    "mlflow.set_tag(\"Train interval\", RETRAIN_INTERVAL)\n",
    "mlflow.set_tag(\"Source data name\", SOURCE_NAME)\n",
    "mlflow.set_tag(\"Source data columns\", SOURCE_COLUMNS)\n",
    "mlflow.set_tag(\"Source data time form\", df.index.min().isoformat())\n",
    "mlflow.set_tag(\"Source data time to\", df.index.max().isoformat())\n",
    "\n",
    "mlflow.set_tag(\"Rand search N iter\", RANDOM_SEARCH_N_ITER)\n",
    "mlflow.set_tag(\"Optuna patience\", PRUNER_PATIENCE)\n",
    "mlflow.set_tag(\"Optuna trials\", OPTUNA_TRIALS)\n",
    "\n",
    "# log time\n",
    "mlflow.set_tag(\"Random search time\", random_search_total_time)\n",
    "mlflow.set_tag(\"Random search top10 time\", random_search_top10_total_time)\n",
    "mlflow.set_tag(\"Bayesian optimization time\", bayes_opt_total_time)\n",
    "mlflow.set_tag(\"Total time\", total_time)\n",
    "\n",
    "# Save intermediate results\n",
    "tmp_dict = random_search_all_model_variations_by_score.to_dict(orient=\"records\")\n",
    "mlflow.log_dict(tmp_dict, \"results/random_search_all_model_variations_by_score.json\")\n",
    "\n",
    "tmp_dict = random_search_all_models_by_time.to_dict(orient=\"records\")\n",
    "mlflow.log_dict(tmp_dict, \"results/random_search_all_models_by_time.json\")\n",
    "\n",
    "tmp_dict = random_search_top_10_models_by_score.to_dict(orient=\"records\")\n",
    "mlflow.log_dict(tmp_dict, \"results/random_search_top_10_models_by_score.json\")\n",
    "\n",
    "tmp_dict = optimization_results_df.to_dict(orient=\"records\")\n",
    "mlflow.log_dict(tmp_dict, \"results/optimization_results_df.json\")\n",
    "\n",
    "# Log parameters\n",
    "params = model.get_params()\n",
    "mlflow.log_params(params)\n",
    "\n",
    "# Log metrics\n",
    "mlflow.log_metric(\"mse\", mse)\n",
    "mlflow.log_metric(\"mae\", mae)\n",
    "mlflow.log_metric(\"rmse\", rmse)\n",
    "mlflow.log_metric(\"mape\", mape)\n",
    "mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "# Log the model\n",
    "signature = infer_signature(X_train_scaled, y_pred)\n",
    "model_info = mlflow.sklearn.log_model(\n",
    " sk_model=model,\n",
    " artifact_path=best_model_name,\n",
    " signature=signature,\n",
    " input_example=X_train_scaled,\n",
    " registered_model_name=MODEL_NAME,\n",
    ")\n",
    "\n",
    "# rmeoving the temp scaler file\n",
    "if os.path.exists(scaler_path):\n",
    "    os.remove(scaler_path)\n",
    "\n",
    "    # Log feature importances as an artifact\n",
    "    # feature_importances = pd.DataFrame(model.feature_importances_, index=boston.feature_names, columns=['importance']).sort_values('importance', ascending=False)\n",
    "    # feature_importances.to_csv(\"feature_importances.csv\")\n",
    "    # mlflow.log_artifact(\"feature_importances.csv\")\n",
    "    \n",
    "    # Log a plot as an artifact\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.barplot(x=feature_importances.importance, y=feature_importances.index)\n",
    "    # plt.title(\"Feature Importances\")\n",
    "    # plt.savefig(\"feature_importances.png\")\n",
    "    # mlflow.log_artifact(\"feature_importances.png\")\n",
    "\n",
    "# Print the run ID\n",
    "print(f\"Logged data and model in run {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9eaf0a-cfcd-4a29-9af2-02a787411bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3204d95-10c7-4068-a7d2-08cd7fb0b45f",
   "metadata": {},
   "source": [
    "## 7. Predicting with loaded scaler and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a44a0-0fae-4b86-8bb4-55ba4b77fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model and the scaler from mlflow\n",
    "model_uri = f\"models:/{MODEL_NAME}/latest\"\n",
    "model_loaded = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# loading the scaler\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Get latest model version and associated run ID\n",
    "model_version_details = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])[0]\n",
    "run_id = model_version_details.run_id\n",
    "\n",
    "# Path to scaler in artifacts\n",
    "artifact_path = \"scaler/scaler.joblib\"\n",
    "\n",
    "# Download scaler artifact\n",
    "scaler_uri = client.download_artifacts(run_id, artifact_path)\n",
    "\n",
    "# Load the scaler\n",
    "scaler_loaded = joblib.load(scaler_uri)\n",
    "\n",
    "print(\"Scaler loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83457a-9bde-431b-abab-cdf1192b6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_new = scaler_loaded.transform(X_test)\n",
    "y_pred_new = model_loaded.predict(X_test_scaled_new)\n",
    "df_pred = pd.DataFrame([y_pred_new, y_test])\n",
    "\n",
    "evaluate(y_test, y_pred_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
